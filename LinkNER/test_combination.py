#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LinkNERç»„åˆå™¨åŠŸèƒ½æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•ç»„åˆå™¨åŠŸèƒ½çš„åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import os
import pickle
import tempfile
import shutil
from combination.comb_voting import CombByVoting
from combination.evaluate_metric import evaluate_chunk_level


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    # æ¨¡æ‹Ÿä¸‰ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    
    # æ¨¡å‹1çš„ç»“æœ
    pred_chunks_1 = [
        ('PER', 0, 2, 0),   # John Smith
        ('LOC', 5, 7, 0),   # New York
        ('ORG', 10, 12, 1), # Google Inc
    ]
    true_chunks_1 = [
        ('PER', 0, 2, 0),
        ('LOC', 5, 7, 0),
        ('ORG', 10, 12, 1),
        ('MISC', 15, 16, 1),  # æ¨¡å‹1æ¼æ£€äº†è¿™ä¸ª
    ]
    
    # æ¨¡å‹2çš„ç»“æœ
    pred_chunks_2 = [
        ('PER', 0, 2, 0),   # John Smith - æ­£ç¡®
        ('LOC', 5, 7, 0),   # New York - æ­£ç¡®
        ('MISC', 15, 16, 1), # æ¨¡å‹2æ£€æµ‹åˆ°äº†è¿™ä¸ª
        ('PER', 18, 19, 1),  # æ¨¡å‹2çš„è¯¯æ£€
    ]
    true_chunks_2 = true_chunks_1  # çœŸå®æ ‡ç­¾ç›¸åŒ
    
    # æ¨¡å‹3çš„ç»“æœ
    pred_chunks_3 = [
        ('PER', 0, 2, 0),   # John Smith - æ­£ç¡®
        ('ORG', 10, 12, 1), # Google Inc - æ­£ç¡®
        ('MISC', 15, 16, 1), # æ­£ç¡®æ£€æµ‹
        ('LOC', 20, 21, 1),  # å¦ä¸€ä¸ªä½ç½®çš„è¯¯æ£€
    ]
    true_chunks_3 = true_chunks_1  # çœŸå®æ ‡ç­¾ç›¸åŒ
    
    return [
        (pred_chunks_1, true_chunks_1),
        (pred_chunks_2, true_chunks_2),
        (pred_chunks_3, true_chunks_3)
    ]


def save_test_models(test_data, temp_dir):
    """ä¿å­˜æµ‹è¯•æ¨¡å‹ç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶"""
    model_files = []
    for i, (pred_chunks, true_chunks) in enumerate(test_data):
        file_path = os.path.join(temp_dir, f"test_model_{i+1}.pkl")
        with open(file_path, 'wb') as f:
            pickle.dump((pred_chunks, true_chunks), f)
        model_files.append(file_path)
    return model_files


def calculate_f1_scores(test_data):
    """è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„F1åˆ†æ•°"""
    f1_scores = []
    for pred_chunks, true_chunks in test_data:
        f1, _, _, _, _, _ = evaluate_chunk_level(pred_chunks, true_chunks)
        f1_scores.append(f1)
    return f1_scores


def test_combination_methods(temp_dir, model_files, f1_scores):
    """æµ‹è¯•æ‰€æœ‰ç»„åˆæ–¹æ³•"""
    print("Testing combination methods...")
    print("=" * 50)
    
    # æµ‹è¯•å‚æ•°
    dataname = "conll03"
    classes = ['PER', 'LOC', 'ORG', 'MISC']
    cmodelname = "TestCombination"
    fn_stand_res = ""
    fn_prob = ""
    result_dir = os.path.join(temp_dir, "results")
    
    # åˆ›å»ºç»„åˆå™¨
    combiner = CombByVoting(
        dataname=dataname,
        file_dir=temp_dir,
        fmodels=[os.path.basename(f) for f in model_files],
        f1s=f1_scores,
        cmodelname=cmodelname,
        classes=classes,
        fn_stand_res=fn_stand_res,
        fn_prob=fn_prob,
        result_dir=result_dir
    )
    
    # æµ‹è¯•æ‰€æœ‰ç»„åˆæ–¹æ³•
    methods = [
        'best_potential',
        'voting_majority',
        'voting_weightByOverallF1',
        'voting_weightByCategotyF1'
    ]
    
    results = {}
    for method in methods:
        print(f"\nTesting method: {method}")
        try:
            result = combiner.combine_results(method=method)
            f1, p, r, correct_preds, total_preds, total_correct = result
            results[method] = result
            print(f"  F1: {f1:.4f}, Precision: {p:.4f}, Recall: {r:.4f}")
            print(f"  Correct: {correct_preds}, Predicted: {total_preds}, True: {total_correct}")
        except Exception as e:
            print(f"  Error: {e}")
            results[method] = None
    
    return results


def test_individual_models(test_data):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„æ€§èƒ½"""
    print("\nIndividual model performance:")
    print("-" * 30)
    
    for i, (pred_chunks, true_chunks) in enumerate(test_data):
        f1, p, r, correct_preds, total_preds, total_correct = evaluate_chunk_level(
            pred_chunks, true_chunks)
        print(f"Model {i+1}: F1={f1:.4f}, P={p:.4f}, R={r:.4f}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("LinkNER Combination Functionality Test")
    print("=" * 50)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    print(f"Using temporary directory: {temp_dir}")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = create_test_data()
        print(f"Created test data with {len(test_data)} models")
        
        # æµ‹è¯•å•ä¸ªæ¨¡å‹æ€§èƒ½
        test_individual_models(test_data)
        
        # ä¿å­˜æµ‹è¯•æ¨¡å‹
        model_files = save_test_models(test_data, temp_dir)
        print(f"\nSaved test models: {[os.path.basename(f) for f in model_files]}")
        
        # è®¡ç®—F1åˆ†æ•°
        f1_scores = calculate_f1_scores(test_data)
        print(f"Individual F1 scores: {[f'{f:.4f}' for f in f1_scores]}")
        
        # æµ‹è¯•ç»„åˆæ–¹æ³•
        results = test_combination_methods(temp_dir, model_files, f1_scores)
        
        # æ€»ç»“ç»“æœ
        print("\n" + "=" * 50)
        print("SUMMARY")
        print("=" * 50)
        
        successful_methods = [method for method, result in results.items() if result is not None]
        failed_methods = [method for method, result in results.items() if result is None]
        
        print(f"Successful methods: {len(successful_methods)}")
        for method in successful_methods:
            f1 = results[method][0]
            print(f"  - {method}: F1={f1:.4f}")
        
        if failed_methods:
            print(f"\nFailed methods: {len(failed_methods)}")
            for method in failed_methods:
                print(f"  - {method}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›
        best_individual_f1 = max(f1_scores)
        best_combination_f1 = max([result[0] for result in results.values() if result is not None])
        
        print(f"\nBest individual model F1: {best_individual_f1:.4f}")
        print(f"Best combination F1: {best_combination_f1:.4f}")
        print(f"Improvement: {best_combination_f1 - best_individual_f1:.4f}")
        
        if best_combination_f1 > best_individual_f1:
            print("âœ… Combination shows improvement!")
        else:
            print("âš ï¸  Combination did not improve over individual models")
        
        print("\nğŸ‰ Test completed successfully!")
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            shutil.rmtree(temp_dir)
            print(f"Cleaned up temporary directory: {temp_dir}")
        except Exception as e:
            print(f"Warning: Could not clean up temporary directory: {e}")


if __name__ == "__main__":
    main()